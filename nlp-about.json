{
    "links":{},
    "photo":"https://s3.amazonaws.com/coursera/topics/nlp/large-icon.png",
    "courseFormat":"",
    "smallIcon":"https://d1z850dzhxs7de.cloudfront.net/topics/nlp/small-icon.hover.png",
    "universityLogo":"",
    "video":"Fnr4A0tcU-M",
    "smallIconHover":"https://d1z850dzhxs7de.cloudfront.net/topics/nlp/small-icon.hover.png",
    "shortDescription":"In this class, you will learn fundamental algorithms and mathematical models for processing natural language, and how these can be used to solve practical problems.",
    "id":7,
    "estimatedClassWorkload":"8-10 hours/week",
    "previewLink":"https://class.coursera.org/nlp/lecture/preview",
    "targetAudience":1,
    "courseSyllabus":"<p>The following topics will be covered in the first two weeks:</p>\n<ol>\n<li><b>Introduction and Overview:</b></li>\n<li><b>Basic Text Processing:&nbsp;</b>J+M Chapters 2.1, 3.9; MR+S Chapters 2.1-2.2</li>\n<li><b>Minimum Edit Distance:&nbsp;</b>J+M Chapter 3.11</li>\n<li><b>Language Modeling:&nbsp;</b>J+M Chapter 4</li>\n<li><b>Spelling Correction:</b>&nbsp;J+M Chapters 5.9,&nbsp;<a href=\"http://norvig.com/spell-correct.html\">Peter Norvig (2007) How to Write a Spelling Corrector</a></li>\n</ol>\n<div class=\"coursera-course-faq\"></div>",
    "aboutTheCourse":"<p>This course covers a broad range of topics in natural language processing, including word and sentence tokenization, text classification and sentiment analysis, spelling correction, information extraction, parsing, meaning extraction, and question answering, We will also introduce the underlying theory from probability, statistics, and machine learning that are crucial for the field, and cover fundamental algorithms like n-gram language modeling, naive bayes and maxent classifiers, sequence models like Hidden Markov Models, probabilistic dependency and constituent parsing, and vector-space models of meaning.</p>\nWe are offering this course on Natural Language Processing free and online to students worldwide, continuing Stanford's exciting forays into large scale online instruction. Students have access to screencast lecture videos, are given quiz questions, assignments and exams, receive regular feedback on progress, and can participate in a discussion forum. Those who successfully complete the course will receive a statement of accomplishment. Taught by Professors Jurafsky and Manning, the curriculum draws from Stanford's courses in Natural Language Processing. You will need a decent internet connection for accessing course materials, but should be able to watch the videos on your smartphone.&nbsp;<br><br>\n<p><strong>&nbsp;</strong></p>",
    "largeIcon":"https://d15cw65ipctsrr.cloudfront.net/35/dec5b0352d11e4b1518bb3518fcc93/large-icon.png",
    "suggestedReadings":"<p>We will provide detailed lecture notes of all the technical content, which will be yours to keep after the end of class. Many students do fine just working from the lectures and notes. But others find it very useful to have an accompanying textbook, for reinforcing the core material, as a source of additional exercises, and as a reference for the future.</p>\nTo prepare for the class in advance, you may consider reading through some sections of the textbooks (<a href=\"http://chggtrx.com/click.track?CID=267582&AFID=301076&ADID=1088031&SID=nlp&isbn_ean=9780131873216\">Jurafsky and Martin, Speech and Language Processing 2nd Edition</a>, and&nbsp;<a href=\"http://chggtrx.com/click.track?CID=267582&AFID=301076&ADID=1088031&SID=nlp&isbn_ean=9780521865715/\">Manning, Sch\u00fctze and Raghavan 2008</a>). Or, if you're rusty or not very experienced in either Java or Python, it'd be great to work through early parts of&nbsp;<a href=\"http://chggtrx.com/click.track?CID=267582&AFID=301076&ADID=1088031&SID=nlp&isbn_ean=9780596516499\">Bird, Klein and Loper 2009</a>",
    "videoId":"Fnr4A0tcU-M",
    "faq":"<ul>\n<li><strong>Will I get a statement of accomplishment after completing this class?</strong>\n<p>Yes. Students who successfully complete the class will receive a statement of accomplishment signed by the instructor.</p>\n</li>\n<li><strong>What is the format of the class?</strong>\n<p>The class will consist of lecture videos, which are broken into small chunks, usually between 8 and 12 minutes each. Some of these may contain integrated quiz questions. There will also be standalone quizzes that are not part of video lectures, and programming assignments.</p>\n</li>\n<li><strong>How much work will I be expected to do in this class?</strong>\n<p>You need to work about 10 hours a week to complete the course.</p>\n</li>\n<ul>\n<li>About 2 hours of video segments each week, containing inline ungraded quiz questions.</li>\n<li>A weekly, graded multiple choice and short answer problem set (about 1 hour to complete).</li>\n<li>A substantial weekly programming assignment (about 6 hours to complete).</li>\n</ul>\n<li>\n<p><strong>Why Study Natural Language Processing?</strong></p>\nNatural language processing is the technology for dealing with our most ubiquitous product: human language, as it appears in emails, web pages, tweets, product descriptions, newspaper stories, social media, and scientific articles, in thousands of languages and varieties. In the past decade, successful natural language processing applications have become part of our everyday experience, from spelling and grammar correction in word processors to machine translation on the web, from email spam detection to automatic question answering, from detecting people's opinions about products or services to extracting appointments from your email. In this class, you'll learn the fundamental algorithms and mathematical models for human language processing and how you can use them to solve practical problems in dealing with language data wherever you encounter it.</li>\n</ul>",
    "shortName":"nlp",
    "instructor":"Dan Jurafsky, Professor. Christopher Manning, Associate Professor",
    "name":"Natural Language Processing",
    "subtitleLanguagesCsv":"",
    "recommendedBackground":"<p>No background in natural language processing is required. Students will be expected to know a bit of basic probability (know Bayes rule), a bit about vectors and vector spaces (could length normalize a vector), a bit of calculus (know that the derivative of a function is zero at a maximum or minimum of a function), but we will review these concepts as we first use them. You should have reasonable programming ability (know about hash tables and graph data structures), be able to write programs in Java or Python, and have a computer (Windows, Mac or Linux) with internet access.</p>\n<p></p>",
    "aboutTheInstructor":"<p>Professors Jurafsky and Manning are the leading natural language processing educators, through their textbooks on natural language processing, speech, and information retrieval.</p>\n<p><img src=\"http://spark-public.s3.amazonaws.com/nlp/landing/jurafsky.png\" class=\"coursera-instructor-thumb\"> <a href=\"http://www.stanford.edu/~jurafsky/\">Dan Jurafsky</a> is Professor of Linguistics and Professor by Courtesy of Computer Science at Stanford University. Dan received his Bachelor's degree in Linguistics in 1983 and his Ph.D. in Computer Science in 1992, both from the University of California at Berkeley, and also taught at the University of Colorado, Boulder before joining the Stanford faculty in 2004. He is the recipient of a MacArthur Fellowship and has served on a variety of editorial boards, corporate advisory boards, and program committees. Dan's research extends broadly throughout natural language processing as well as its application to the behavioral and social sciences.</p>\n<p><img src=\"http://spark-public.s3.amazonaws.com/nlp/landing/manning.png\" class=\"coursera-instructor-thumb\"> <a href=\"http://nlp.stanford.edu/~manning/\">Christopher Manning</a> is an Associate Professor of Computer Science and Linguistics at Stanford University. Chris received a Bachelors degree and University Medal from the Australian National University and a Ph.D. from Stanford in 1994, both in Linguistics. Chris taught at Carnegie Mellon University and The University of Sydney before joining the Stanford faculty in 1999. He is a Fellow of the American Association for Artificial Intelligence and of the Association for Computational Linguistics, and is one of the most cited authors in natural language processing, for his research on a broad range of statistical natural language topics from tagging and parsing to grammar induction and text understanding.</p>"
}